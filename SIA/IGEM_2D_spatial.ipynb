{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perlin_noise import PerlinNoise\n",
    "import netCDF4\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_peak_gpu_memory():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  # in MB\n",
    "    print(f\"Peak GPU memory used: {peak_memory:.2f} MB.\")\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset after printing\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()  # Initialize NVML\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)  # Get memory info\n",
    "    print(f\"GPU memory occupied: {info.used // 1024**2} MB.\")\n",
    "\n",
    "def visualize(Z_surf,time,H_ice,Lx,Ly):\n",
    "        clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "        plt.figure(2, figsize=(11, 4), dpi=200)\n",
    "        # First subplot: Ice surface\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(Z_surf.cpu().numpy(), extent=[0, Lx/1000, 0, Ly/1000], cmap='terrain', origin='lower')\n",
    "        plt.colorbar(label='Elevation (m)')\n",
    "        plt.title('Ice Surface at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "        # Second subplot: Ice thickness\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.where(H_ice.cpu().numpy() > 0, H_ice.cpu().numpy(), np.nan), extent=[0, Lx/1000, 0, Ly/1000], cmap='jet', origin='lower')\n",
    "        plt.colorbar(label='Ice Thickness (m)')\n",
    "        plt.title('Ice Thickness at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "# Function to create and plot a 2D smooth random ELA field\n",
    "def generate_and_plot_ELA_field(Z_topo, Z_ELA, ELA_range=200, octaves=4, seed=42, device='cpu'):\n",
    "    # Get the dimensions of Z_topo\n",
    "    height, width = Z_topo.shape\n",
    "\n",
    "    # Initialize Perlin noise\n",
    "    noise = PerlinNoise(octaves=octaves, seed=seed)\n",
    "\n",
    "    # Generate a 2D noise field\n",
    "    noise_field = torch.tensor(\n",
    "        [[noise([i / height, j / width]) for j in range(width)] for i in range(height)],\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "\n",
    "    # Normalize the noise field to be between -1 and 1\n",
    "    min_noise = torch.min(noise_field)\n",
    "    max_noise = torch.max(noise_field)\n",
    "    normalized_noise = 2 * (noise_field - min_noise) / (max_noise - min_noise) - 1\n",
    "\n",
    "    # Scale the noise to the range [Z_ELA - ELA_range, Z_ELA + ELA_range]\n",
    "    ELA_field = Z_ELA + ELA_range * normalized_noise\n",
    "\n",
    "    # # Plot the ELA field\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # plt.imshow(ELA_field.cpu(), cmap='viridis', origin='lower')\n",
    "    # plt.colorbar(label='ELA (m)')\n",
    "    # plt.title('2D Smooth Random ELA Field')\n",
    "    # plt.xlabel('X Coordinate')\n",
    "    # plt.ylabel('Y Coordinate')\n",
    "    # plt.show()\n",
    "\n",
    "    return ELA_field\n",
    "\n",
    "# Prepare hooks for tensors \n",
    "def print_hook_b(grad):\n",
    "    print(\"\\n db/dELA:\",torch.mean(grad))\n",
    "    return grad\n",
    "def print_hook_h(grad):\n",
    "    print(\"\\n dH/db:\",torch.mean(grad))\n",
    "    return grad\n",
    "def sqrt_hook(grad):\n",
    "    if torch.abs(torch.mean(grad))>1:\n",
    "        print(grad**0.5)\n",
    "        return grad**0.5\n",
    "def reduce_hook(grad):\n",
    "    return grad*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters\n",
    "\n",
    "nc_file = netCDF4.Dataset('bedrock.nc')\n",
    "Z_topo = torch.tensor(nc_file.variables['topg'][:], device=device, dtype=torch.float32)\n",
    "ttot = 425  # Time limit (yr)\n",
    "grad_b = 0.001  # Mass balance gradient\n",
    "b_max = 0.5  # Maximum precip (m/yr)\n",
    "# ELA = 3000  # Elevation of equilibrium line altitude (m)\n",
    "# Generate and plot the ELA field\n",
    "Z_ELA =1800 #generate_and_plot_ELA_field(Z_topo, ELA,device=device)\n",
    "rho, g, fd = 910.0, 9.81, 1e-18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA, rho=rho, g=g, fd=fd,Lx=902000, Ly=602000, dx=2000, dy=2000,dtmax = 1,device=device):\n",
    "    \"\"\"\n",
    "    Solve the glacier dynamics using a diffusion-based solver with PyTorch.\n",
    "    \"\"\"\n",
    "    # Physical parameters (unchanged)\n",
    "\n",
    "    nx = int(Lx / dx)\n",
    "    ny = int(Ly / dy)\n",
    "    epsilon= 1.e-40\n",
    "\n",
    "    # Initialize ice thickness and surface\n",
    "    H_ice = torch.zeros((ny, nx), device=device, dtype=torch.float32)\n",
    "    Z_surf = Z_topo + H_ice\n",
    "    # Initialize time and iteration counter\n",
    "    time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
    "    dt = torch.tensor(dtmax, device=device, dtype=torch.float32)\n",
    "    it = 0\n",
    "\n",
    "    while time < ttot:\n",
    "        time += dt\n",
    "        it += 1\n",
    "\n",
    "        # Compute H_avg\n",
    "        H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "\n",
    "        # Compute Snorm\n",
    "        Sx = (Z_surf[:, 1:] - Z_surf[:, :-1]) / dx\n",
    "        Sy = (Z_surf[1:, :] - Z_surf[:-1, :]) / dy\n",
    "        Sx = 0.5 * (Sx[:-1, :] + Sx[1:, :])\n",
    "        Sy = 0.5 * (Sy[:, :-1] + Sy[:, 1:])\n",
    "        Snorm = torch.sqrt(Sx**2 + Sy**2 + epsilon)  # Add a small value to avoid division by zero\n",
    "\n",
    "        # Compute diffusivity\n",
    "        D = fd * (rho * g)**3.0 * H_avg**5 * Snorm**2+ epsilon\n",
    "\n",
    "        # Compute adaptive time step\n",
    "        dt = min(min(dx, dy)**2 / (4.1 * torch.max(D).item()), dtmax)\n",
    "\n",
    "        # Compute fluxes\n",
    "        qx = -(0.5 * (D[:-1, :] + D[1:, :])) * (Z_surf[1:-1, 1:] - Z_surf[1:-1, :-1]) / dx\n",
    "        qy = -(0.5 * (D[:, :-1] + D[:, 1:])) * (Z_surf[1:, 1:-1] - Z_surf[:-1, 1:-1]) / dy\n",
    "\n",
    "        # Compute thickness change rate\n",
    "        dHdt = -(torch.diff(qx, dim=1) / dx + torch.diff(qy, dim=0) / dy)\n",
    "\n",
    "        # Update ice thickness\n",
    "        H_ice[1:-1, 1:-1] += dt * dHdt\n",
    "\n",
    "        # Compute surface mass balance (SMB)\n",
    "        b = torch.minimum(grad_b * (Z_surf - Z_ELA), torch.tensor(b_max, device=device))\n",
    "        b.retain_grad() \n",
    "        b.register_hook(reduce_hook)\n",
    "\n",
    "        H_ice[1:-1, 1:-1] += dt * b[1:-1, 1:-1]\n",
    "\n",
    "        # Ensure ice thickness remains positive\n",
    "        H_ice = torch.maximum(H_ice, torch.tensor(0.0, device=device))\n",
    "        # Update surface topography\n",
    "        Z_surf = Z_topo + H_ice\n",
    "\n",
    "        # Visualization at specified intervals\n",
    "        # if it % 50 == 0:\n",
    "        #     visualize(Z_surf,time,H_ice,Lx,Ly)\n",
    "    return H_ice, it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469\n"
     ]
    }
   ],
   "source": [
    "Z_ELA = torch.full(Z_topo.shape,2000., requires_grad=True, device=device)\n",
    "h,it=solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA)\n",
    "print(it)\n",
    "# torch.save(h,'Obs_2D.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gpu_utilization()\n",
    "print_peak_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversion with ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the starting point in tracking maximum GPU memory occupied by tensors in bytes for a given device.\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "# Initial guesses for inversion problem\n",
    "Z_ELA = torch.full(Z_topo.shape,2200., requires_grad=True, device=device)\n",
    "\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk = torch.load('Obs_2D.pt', weights_only=True).to(device) # Ensure it's on the right device\n",
    "\n",
    "# Define initial and final learning rates\n",
    "initial_lr = 7\n",
    "final_lr = 5\n",
    "reg_lambda=0.000005\n",
    "n_iterations = 10\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam([Z_ELA], lr=initial_lr)\n",
    "\n",
    "# Initialize lists to track loss components\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "total_gradients_history=[]\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Update the learning rate\n",
    "    lr = initial_lr - (i / (n_iterations - 1)) * (initial_lr - final_lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    \n",
    "    # Perform forward simulation\n",
    "    H_simulated, it= solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA)\n",
    "\n",
    "    print(it)\n",
    "    # Compute data fidelity term\n",
    "    data_fidelity = torch.mean((H_simulated - observed_thk) ** 2)\n",
    "\n",
    "    # Compute smoothness regularization (differences in x and y directions)\n",
    "    smoothness_x = torch.sum((Z_ELA[:, 1:] - Z_ELA[:, :-1]) ** 2)\n",
    "    smoothness_y = torch.sum((Z_ELA[1:, :] - Z_ELA[:-1, :]) ** 2)\n",
    "    smoothness_reg = smoothness_x + smoothness_y\n",
    "\n",
    "    # Total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "     \n",
    "    # Backpropagate loss and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Store the gradients and ELA evolution\n",
    "    total_gradients_history.append(torch.max(Z_ELA.grad).item())\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store loss components for plotting later\n",
    "    total_loss_history.append(loss.item())\n",
    "    data_fidelity_history.append(data_fidelity.item())\n",
    "    regularization_history.append((reg_lambda * smoothness_reg).item())\n",
    "    # Print loss, gradients and current parameters every 50 iterations \n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f\"\\nIteration {i+1}/{n_iterations}, Loss: {loss:.3f}, ELA: {torch.mean(Z_ELA).item()}; {torch.min(Z_ELA).item()}\")\n",
    "        print(f\"Gradient of ELA : {torch.max(Z_ELA.grad).item()}\")\n",
    "\n",
    "        print_gpu_utilization()  # Print memory after the loop\n",
    "        print_peak_gpu_memory()  # Print the peak memory   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(ELA_evolution,label=\"evolution of ELA\",color='b')\n",
    "plt.plot(total_gradients_history, label='Evolution of gradients')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the loss function components\n",
    "def plot_loss_components(total_loss_history, data_fidelity_history, regularization_history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the total loss, data fidelity, and regularization term\n",
    "    plt.plot(total_loss_history, label='Total Loss', color='b', linewidth=2)\n",
    "    plt.plot(data_fidelity_history, label='Data Fidelity', color='g', linestyle='--', linewidth=2)\n",
    "    plt.plot(regularization_history, label='Regularization (Smoothness)', color='r', linestyle='-.', linewidth=2)\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.title('Loss Function Components Over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ELA field\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Detach the tensor from the computation graph and move it to the CPU before converting to a NumPy array\n",
    "plt.imshow(Z_ELA.detach().cpu().numpy(), cmap='viridis', origin='lower')\n",
    "plt.colorbar(label='ELA (m)')\n",
    "plt.title('Reconstructed ELA Field')\n",
    "plt.savefig('inverted_ELA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ELA\n",
    "torch.save(Z_ELA,\"inverted_ELA.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do: \n",
    "\n",
    "- include a more complex smb forcing (pdd)\n",
    "- include saliency / atribute maps from gradients\n",
    "- Design a new experiment where I reconstruct temperature and precipitiation, evolution maps (screenshots) during deglaciation.\n",
    "- Use observed glacier extent from the years in the inversion problem. Try to reconstruct the climate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on cuda device\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from utils import print_gpu_utilization, print_peak_gpu_memory, device\n",
    "from visualization import plot_gradient_evolution,plot_loss_components,visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the integral is :  90.50938584758993\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "T_ma = 5    # Mean annual temperature in degrees Celsius\n",
    "T_mj = 20   # Temperature in the hottest month in degrees Celsius\n",
    "A = 12      # Period in months (one year)\n",
    "\n",
    "# Time array: monthly resolution for a full year\n",
    "t = np.linspace(0, A, 300)\n",
    "\n",
    "# Temperature function\n",
    "T_abl = T_ma - (T_mj - T_ma) * np.cos(2 * np.pi * t / A)\n",
    "\n",
    "# Compute t1 and t2\n",
    "t1 = (A / (2 * np.pi)) * np.arccos(T_ma / (T_mj - T_ma))\n",
    "t2 = A - t1\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t, T_abl, label=r'$T(t)$', color='darkorange')\n",
    "plt.axhline(y=0, color='blue', linestyle='--', label=r'$T_{0°C}$')\n",
    "\n",
    "# Fill area under curve between t1 and t2\n",
    "mask_red = (t >= t1) & (t <= t2)\n",
    "plt.fill_between(t, T_abl, 0, where=mask_red, interpolate=True, color='#FF6464', alpha=0.4, label='Melt days')\n",
    "\n",
    "# Fill area between curve and T=0 for t in [0, t1]\n",
    "mask_blue1 = (t >= 0) & (t <= t1)\n",
    "plt.fill_between(t, T_abl, 0, where=mask_blue1, interpolate=True, color='#659DF2', alpha=0.4, label='Accumulation days')\n",
    "mask_blue2 = (t >= t2) & (t <= A)\n",
    "plt.fill_between(t, T_abl, 0, where=mask_blue2, interpolate=True, color='#659DF2', alpha=0.4)\n",
    "\n",
    "\n",
    "# Annotations\n",
    "plt.text(t1 - 0.3, 0.5, r'$t_1$', color='black', fontsize=16)\n",
    "plt.text(t2, 0.5, r'$t_2$', color='black', fontsize=16)\n",
    "plt.text(t1 - 0.09, -0.25, r'$x$', color='black', fontsize=10)\n",
    "plt.text(t2 - 0.09, -0.25, r'$x$', color='black', fontsize=10)\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Annual Temperature Cycle')\n",
    "plt.xlabel('Time (months)')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('annual_temp.png')\n",
    "plt.show()\n",
    "\n",
    "ratio= T_ma / (T_mj - T_ma)\n",
    "integral = (\n",
    "            T_ma * (A - (A / np.pi) * np.arccos(ratio)) +\n",
    "            ((T_mj - T_ma) * A / np.pi) * np.sqrt(1 - ratio**2))\n",
    "print(\"the integral is : \",integral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integral_positive_temperature(T_ma, T_mj):\n",
    "    \"\"\"\n",
    "    Computes the integral of T_abl(t) over the period where T_abl > 0 (PyTorch version).\n",
    "    \"\"\"\n",
    "    A = 12.0  # months\n",
    "    ratio = T_ma / (T_mj - T_ma)\n",
    "    integral = torch.zeros_like(T_ma)\n",
    "\n",
    "    valid = ratio < 1\n",
    "    ratio_valid = torch.clamp(ratio[valid], -1.0, 1.0)\n",
    "\n",
    "    integral[valid] = (\n",
    "        T_ma[valid] * (A - (A / torch.pi) * torch.acos(ratio_valid)) +\n",
    "        ((T_mj[valid] - T_ma[valid]) * A / torch.pi) * torch.sqrt(1 - ratio_valid**2)\n",
    "    )\n",
    "\n",
    "    return integral\n",
    "\n",
    "def apply_lapse_rate(topography, T_ma_lowest, T_mj_lowest):\n",
    "    lapse_rate = 7.0 / 1000.0  # 6°C/km\n",
    "    min_altitude = torch.min(topography)\n",
    "    delta_alt = topography - min_altitude\n",
    "\n",
    "    T_ma = T_ma_lowest - lapse_rate * delta_alt\n",
    "    T_mj = T_mj_lowest - lapse_rate * delta_alt\n",
    "\n",
    "    return T_ma, T_mj\n",
    "\n",
    "def compute_negative_temperature_ratio(T_ma, T_mj):\n",
    "    \"\"\"\n",
    "    Computes the ratio of the year when the temperature is negative (PyTorch version).\n",
    "    Parameters:\n",
    "        T_ma (Tensor): 2D tensor of mean annual temperatures (on device)\n",
    "        T_mj (Tensor): 2D tensor of hottest month temperatures (on device)\n",
    "    Returns:\n",
    "        Tensor: 2D tensor of negative temperature ratios (values between 0 and 1)\n",
    "    \"\"\"\n",
    "    ratio = T_ma / (T_mj - T_ma)\n",
    "    neg_temp_ratio = torch.zeros_like(T_ma)\n",
    "    # Case 1: Always positive temp\n",
    "    mask_always_positive = ratio >= 1\n",
    "    neg_temp_ratio[mask_always_positive] = 0.0\n",
    "    # Case 2: Always negative temperatures\n",
    "    mask_always_negative = ratio <= -1\n",
    "    neg_temp_ratio[mask_always_negative] = 1.0\n",
    "    # Case 3: Valid\n",
    "    mask_valid = (~mask_always_positive) & (~mask_always_negative)\n",
    "    ratio_valid = torch.clamp(ratio[mask_valid], -1.0, 1.0)\n",
    "    neg_temp_ratio[mask_valid] = (1.0 / torch.pi) * torch.acos(ratio_valid)\n",
    "\n",
    "    return neg_temp_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SMB parameters directly\n",
    "melt_f =2/12 # m water / (C year)\n",
    "smb_oggm_wat_density = 1000.0\n",
    "smb_oggm_ice_density = 910.0  #kg/m^3\n",
    "def update_smb(Z_topo,precipitation, T_ma_lowest,T_mj_lowest):\n",
    "    \"\"\"Compute the surface mass balance (SMB)\n",
    "         Input:  precipitation [Unit: m * y^(-1)]\n",
    "                 air_temp      [Unit: °C           ]\n",
    "         Output  smb           [Unit: m ice eq. / y]\n",
    "    This mass balance routine implements the surface mass balance model of OGGM\n",
    "    \"\"\"\n",
    "\n",
    "    T_ma, T_mj = apply_lapse_rate(Z_topo, T_ma_lowest, T_mj_lowest)\n",
    "    \n",
    "    # Compute accumulation\n",
    "\n",
    "    accumulation= precipitation* compute_negative_temperature_ratio(T_ma, T_mj) # unit: [ m * y^(-1) water ]\n",
    "    \n",
    "\n",
    "    # Compute ablation\n",
    "    ablation = melt_f  *  compute_integral_positive_temperature(T_ma, T_mj)# unit: [m water / (C year)] * [C year]  => m water \n",
    "    # Compute SMB and convert to ice equivalent\n",
    "    smb = (accumulation - ablation).sum(dim=0) * (smb_oggm_wat_density / smb_oggm_ice_density)\n",
    "    \n",
    "    return smb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = 2.3 # e.g., m/year\n",
    "T_ma_lowest = 4 # °C at lowest elevation\n",
    "T_mj_lowest = 16  # °C at lowest elevation\n",
    "\n",
    "nc_file = netCDF4.Dataset('geology.nc')\n",
    "# nc_file = netCDF4.Dataset('AIF-v1/output-500.nc')\n",
    "Z_topo = torch.tensor(nc_file.variables['topg'][:], device=device)\n",
    "\n",
    "# Constant precipitation\n",
    "precip_tensor = torch.full((1,*Z_topo.shape), precip, device=device)\n",
    "\n",
    "\n",
    "smb = update_smb(Z_topo,precip_tensor,T_ma_lowest,T_mj_lowest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smb_npy = (smb).to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(smb_npy)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5274725"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_npy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare hooks for tensors \n",
    "def print_hook_b(grad):\n",
    "    print(\"\\n Gradient is :\", torch.norm(grad))\n",
    "    return grad\n",
    "\n",
    "def reduce_hook(grad):\n",
    "    return grad * 1/5\n",
    "\n",
    "def increase_hook(grad):\n",
    "    return grad * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the spatial-temporal observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = netCDF4.Dataset('geology_200m.nc')\n",
    "Z_topo = torch.tensor(nc_file.variables['topg'][:], device=device)\n",
    "thk_1880 = torch.tensor(nc_file.variables['thk_1880'][:], device=device)\n",
    "ice_mask = torch.tensor(nc_file.variables['icemask'][:], device=device)\n",
    "\n",
    "ttot = 120  # Time limit (yr)\n",
    "t_start=1880.\n",
    "\n",
    "rho, g, fd = torch.tensor([910.0, 9.81,0.25e-16], device=device) # units [kg/m^3, m/s^-2, Pa^-3year^-1]\n",
    "dx=200\n",
    "dy=200\n",
    "Lx=Z_topo.shape[1]*dx\n",
    "Ly=Z_topo.shape[0]*dy\n",
    "nc_file.close()\n",
    "torch.save(thk_1880,'Obs_2D.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to NumPy\n",
    "Z_topo_npy = Z_topo.to(torch.float32).cpu().numpy()\n",
    "thk_1880_npy = thk_1880.to(torch.float32).cpu().numpy()\n",
    "\n",
    "# Define the extent: [xmin, xmax, ymin, ymax]\n",
    "extent = [0, Lx/100, 0, Ly/100]\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot topography\n",
    "img = ax.imshow((Z_topo_npy + thk_1880_npy)/100, cmap='terrain', origin='lower',extent=extent)\n",
    "\n",
    "# Create divider for colorbar and reduce padding\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)  # pad controls the spacing\n",
    "cbar = fig.colorbar(img, cax=cax)\n",
    "cbar.set_label('Topography /100 [m]')\n",
    "\n",
    "# Overlay glacier thickness\n",
    "thk_display = np.ma.masked_where(thk_1880_npy <= 0, thk_1880_npy)\n",
    "ax.imshow(thk_display, cmap='Blues', alpha=1, origin='lower',extent=extent)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Aletsch Glacier (1880)\")\n",
    "ax.set_xlabel(\"X /100 [m]\")\n",
    "ax.set_ylabel(\"Y /100 [m]\")\n",
    "# Add the red star marker\n",
    "ax.plot(40,190, marker='*', color='red', markersize=15, markeredgecolor='black')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlacierDynamicsCheckpointed(torch.nn.Module):\n",
    "    def __init__(self, Z_topo, ttot, rho, g, fd, Lx, Ly, dx, dy, dtmax, device, ice_mask):\n",
    "        super().__init__()\n",
    "        self.Z_topo = Z_topo\n",
    "        self.ice_mask=ice_mask\n",
    "        self.ttot = ttot\n",
    "        # self.grad_b = grad_b\n",
    "        # self.b_max = b_max\n",
    "        self.rho = rho\n",
    "        self.g = g\n",
    "        self.fd = fd\n",
    "        self.Lx = Lx\n",
    "        self.Ly = Ly\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "        self.dtmax = dtmax\n",
    "        self.device = device\n",
    "        \n",
    "\n",
    "    def forward(self, precip_tensor, T_ma_lowest,T_mj_lowest):\n",
    "        return self.solve_glacier_dynamics(self.Z_topo, self.ttot,precip_tensor, T_ma_lowest,T_mj_lowest)\n",
    "\n",
    "    def solve_glacier_dynamics(self, Z_topo, ttot,precip_tensor, T_ma_lowest,T_mj_lowest):\n",
    "        nx = int(self.Lx / self.dx)\n",
    "        ny = int(self.Ly / self.dy)\n",
    "\n",
    "        epsilon = torch.tensor(1.e-10, device=self.device)\n",
    "        H_ice = torch.zeros((ny, nx), device=self.device)\n",
    "        # H_ice = H_initial.to(device=device)\n",
    "        \n",
    "        Z_surf = Z_topo + H_ice\n",
    "\n",
    "        time = torch.tensor(0., device=self.device)\n",
    "        # dt = torch.tensor(self.dtmax, device=self.device)\n",
    "        it = torch.tensor(0., device=self.device)\n",
    "        t_freq=torch.tensor(5., device=self.device)\n",
    "        t_last_update=torch.tensor(0., device=self.device)\n",
    "        #initial smb \n",
    "        smb = update_smb(Z_surf,precip_tensor,T_ma_lowest,T_mj_lowest)*self.ice_mask\n",
    "\n",
    "        def checkpointed_step(H_ice, Z_surf,smb, time):\n",
    "            # Compute H_avg\n",
    "            H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "\n",
    "            # Compute Snorm\n",
    "            Sx = (Z_surf[:, 1:] - Z_surf[:, :-1]) / self.dx\n",
    "            Sy = (Z_surf[1:, :] - Z_surf[:-1, :]) / self.dy\n",
    "            Sx = 0.5 * (Sx[:-1, :] + Sx[1:, :])\n",
    "            Sy = 0.5 * (Sy[:, :-1] + Sy[:, 1:])\n",
    "            Snorm = torch.sqrt(Sx**2 + Sy**2 + epsilon)\n",
    "\n",
    "               \n",
    "            # Compute diffusivity\n",
    "            D = self.fd * (self.rho * self.g)**3.0 * H_avg**5 * Snorm**2 + epsilon\n",
    "\n",
    "            \n",
    "\n",
    "            # Compute adaptive time step.\n",
    "            dt_value = min(min(self.dx, self.dy)**2 / (2.7 * torch.max(D).item()), self.dtmax)\n",
    "            dt = torch.tensor(dt_value, dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "\n",
    "            # Compute fluxes\n",
    "            qx = -(0.5 * (D[:-1, :] + D[1:, :])) * (Z_surf[1:-1, 1:] - Z_surf[1:-1, :-1]) / self.dx\n",
    "            qy = -(0.5 * (D[:, :-1] + D[:, 1:])) * (Z_surf[1:, 1:-1] - Z_surf[:-1, 1:-1]) / self.dy\n",
    "\n",
    "            # Compute thickness change rate\n",
    "            dHdt = -(torch.diff(qx, dim=1) / self.dx + torch.diff(qy, dim=0) / self.dy)\n",
    "\n",
    "            # Update ice thickness\n",
    "            H_ice = H_ice.clone()\n",
    "            H_ice[1:-1, 1:-1] = H_ice[1:-1, 1:-1] + dt * dHdt\n",
    "\n",
    "            H_ice = H_ice.clone()\n",
    "            H_ice[1:-1, 1:-1] = H_ice[1:-1, 1:-1] + dt * smb[1:-1, 1:-1]\n",
    "\n",
    "            # Ensure ice thickness remains positive\n",
    "            H_ice = torch.maximum(H_ice, torch.tensor(0.0, dtype=torch.float32, device=self.device))\n",
    "\n",
    "            # Update surface topography\n",
    "            Z_surf = Z_topo + H_ice\n",
    "            # print(f\"Max H avarage : {torch.max(H_avg).item()} andMax of D : {torch.max(D).item()}, dt : {dt.item()}, max smb : {torch.max(smb).item()}\")\n",
    "            return H_ice, Z_surf, time + dt\n",
    "\n",
    "        while time < ttot:           \n",
    "            \n",
    "            unroll = 1000          # window length\n",
    "\n",
    "            H_ice, Z_surf, time = checkpoint(checkpointed_step, H_ice, Z_surf, smb, time)\n",
    "            it += 1\n",
    "            # Compute surface mass balance (SMB)\n",
    "            if (time-t_last_update)>=t_freq:\n",
    "                smb = update_smb(Z_surf,precip_tensor,T_ma_lowest,T_mj_lowest) * self.ice_mask\n",
    "                t_last_update=time.clone()\n",
    "                \n",
    "            if it % unroll == 0:\n",
    "            #     # cut the graph\n",
    "                H_ice = H_ice.detach().requires_grad_()\n",
    "                Z_surf = Z_surf.detach().requires_grad_()\n",
    "            #     # precip_tensor.detach().requires_grad_()\n",
    "            #     # T_ma_lowest.detach().requires_grad_()\n",
    "            #     # T_mj_lowest.detach().requires_grad_()\n",
    "        return H_ice\n",
    "\n",
    "# Wrap the solve_glacier_dynamics function in the checkpointed module\n",
    "glacier_model = GlacierDynamicsCheckpointed(Z_topo, ttot, rho, g, fd, Lx, Ly, dx, dy, 1, device,ice_mask)\n",
    "\n",
    "# Replace the direct call with a call to the checkpointed model\n",
    "# H_simulated, it = glacier_model(precip_tensor, T_ma_lowest,T_mj_lowest)\n",
    "# torch.save(H_simulated,'Obs_2D.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inversion options \n",
    "**Mean Square Error (MSE)**:\n",
    "\n",
    "* Recomended for the case where we have glacier thickness. Converges the fastest.  \n",
    "\n",
    "\n",
    "**Intersection over Union (IoU)**: \n",
    "\n",
    "* Also known as the **Jaccard Index**, this measures the overlap between simulated and observed extents. We use this option when we do not have information about the glacier thickness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function for the forward computation to use with checkpointing\n",
    "def inversion_thicknes(precip_tensor, T_ma_lowest,T_mj_lowest,observed_thk, reg_lambda):\n",
    "    # Perform forward simulation\n",
    "    H_simulated = glacier_model(precip_tensor, T_ma_lowest,T_mj_lowest)\n",
    "\n",
    "    # Compute data fidelity term\n",
    "    data_fidelity = torch.mean(torch.abs(H_simulated - observed_thk) ** 2)/torch.norm(observed_thk)\n",
    "\n",
    "    # Compute smoothness regularization\n",
    "    smoothness_x = torch.sum((precip_tensor[:, 1:] - precip_tensor[:, :-1]) ** 2)\n",
    "    smoothness_y = torch.sum((precip_tensor[1:, :] - precip_tensor[:-1, :]) ** 2)\n",
    "    smoothness_reg = smoothness_x + smoothness_y\n",
    "\n",
    "    # Total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "    return loss,H_simulated\n",
    "\n",
    "# Define a function for the forward computation to use with checkpointing\n",
    "def inversion_extent(precip_tensor,temp_low,temp_high, observed_thk):\n",
    "    \"\"\"\n",
    "    Forward computation with IoU for data fidelity and smoothness regularization.\n",
    "\n",
    "    Args:\n",
    "        Z_ELA (torch.Tensor): The equilibrium line altitude field.\n",
    "        observed_thk (torch.Tensor): The observed glacier thickness.\n",
    "        reg_lambda (float): Regularization parameter for smoothness.\n",
    "        threshold (float): Thickness threshold to define glacier extent.\n",
    "\n",
    "    Returns:\n",
    "        loss (torch.Tensor): Total loss including IoU and regularization.\n",
    "        H_simulated (torch.Tensor): Simulated glacier thickness.\n",
    "    \"\"\"\n",
    "    # Perform forward simulation\n",
    "    H_simulated =  glacier_model(precip_tensor, T_ma_lowest,T_mj_lowest)  # Use the checkpointed glacier model\n",
    "    \n",
    "    # Steeper sigmoid using a scaling factor\n",
    "    scale = 100.0\n",
    "    mask_simulated = torch.sigmoid(scale * (H_simulated - 1))\n",
    "    mask_observed = torch.sigmoid(scale * (observed_thk - 1))\n",
    "\n",
    "    # Compute data fidelity term\n",
    "    data_fidelity = torch.mean(torch.abs(mask_simulated - mask_observed) ** 2)\n",
    "    # Compute smoothness regularization\n",
    "    smoothness_x = torch.sum((precip_tensor[:, 1:] - precip_tensor[:, :-1]) ** 2)\n",
    "    smoothness_y = torch.sum((precip_tensor[1:, :] - precip_tensor[:-1, :]) ** 2)\n",
    "    smoothness_reg = smoothness_x + smoothness_y\n",
    "    \n",
    "    reg_lambda=0.000\n",
    "    # Total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "\n",
    "    return loss, H_simulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7369/381496516.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  precip_tensor = torch.load('percip.pt').to(device).requires_grad_()\n",
      "/tmp/ipykernel_7369/381496516.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  observed_thk = torch.load('Obs_2D.pt').to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb iterations: 1 --------------------------------------------------\n",
      "Gradient norm of parameter: 0.7702\n",
      "Iteration 1 took 208.50 seconds. precip mean = 2.285\n",
      "1321.8470458984375\n",
      "Nb iterations: 2 --------------------------------------------------\n",
      "Gradient norm of parameter: 41.7566\n",
      "Iteration 2 took 171.86 seconds. precip mean = 2.285\n",
      "1337.698486328125\n",
      "Nb iterations: 3 --------------------------------------------------\n",
      "Gradient norm of parameter: 20.2322\n",
      "Iteration 3 took 183.52 seconds. precip mean = 2.284\n",
      "1325.800537109375\n",
      "Nb iterations: 4 --------------------------------------------------\n",
      "Gradient norm of parameter: 22.9559\n",
      "Iteration 4 took 192.30 seconds. precip mean = 2.284\n",
      "1315.8983154296875\n",
      "Nb iterations: 5 --------------------------------------------------\n",
      "Gradient norm of parameter: 28.6739\n",
      "Iteration 5 took 211.26 seconds. precip mean = 2.284\n",
      "1312.5484619140625\n"
     ]
    }
   ],
   "source": [
    "# Reset the starting point in tracking maximum GPU memory occupied by tensors in bytes for a given device.\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Initial guesses for inversion problem\n",
    "# precip_tensor = torch.full((1, *Z_topo.shape), precip, requires_grad=True, device=device)\n",
    "precip_tensor = torch.load('percip.pt').to(device).requires_grad_()\n",
    "\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk = torch.load('Obs_2D.pt').to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "initial_lr = 0.1\n",
    "reg_lambda = 1\n",
    "n_iterations = 5\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam([precip_tensor], lr=initial_lr)\n",
    "# optimizer = torch.optim.Adam([precip_tensor, T_ma_lowest, T_mj_lowest], lr=initial_lr)\n",
    "\n",
    "# Tracking variables\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "total_gradients_history = []\n",
    "\n",
    "# Main loop\n",
    "for i in range(n_iterations):\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'Nb iterations: {i + 1} {50*'-'}')\n",
    "\n",
    "\n",
    "    # Forward pass with gradient checkpointing\n",
    "    loss, H_simulated = inversion_thicknes(precip_tensor, T_ma_lowest, T_mj_lowest, observed_thk, reg_lambda)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Collect gradient norms\n",
    "    grad_norms = []\n",
    "    for param in optimizer.param_groups[0]['params']:\n",
    "        norm = torch.norm(param.grad)\n",
    "        print(f'Gradient norm of parameter: {norm:.4f}')\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log timing\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Iteration {i + 1} took {elapsed_time:.2f} seconds. precip mean = {precip_tensor.mean().item():.3f}\")\n",
    "    # Store history\n",
    "    total_loss_history.append(loss.item())\n",
    "    total_gradients_history.append(torch.norm(precip_tensor.grad).item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # visualize(precip_tensor[0],i,H_simulated,Lx,Ly)\n",
    "        data_fidelity = torch.mean((H_simulated - observed_thk) ** 2).item()\n",
    "        data_fidelity_history.append(data_fidelity)\n",
    "        print(data_fidelity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# Main loop\n",
    "for i in range(1):\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'Nb iterations: {i + 1} {50*\"-\"}')\n",
    "\n",
    "    # Forward pass\n",
    "    loss, H_simulated = checkpointed_inversion_thicknes(\n",
    "        precip_tensor, T_ma_lowest, T_mj_lowest, observed_thk, reg_lambda\n",
    "    )\n",
    "\n",
    "    # 🎯 Export autograd graph BEFORE backward (first iteration only)\n",
    "    if i == 0:\n",
    "        dot = make_dot(loss, params={\n",
    "            'precip_tensor': precip_tensor,\n",
    "            'T_ma_lowest': T_ma_lowest,\n",
    "            'T_mj_lowest': T_mj_lowest\n",
    "        })\n",
    "        dot.render(\"glacier_inversion_graph\", format=\"pdf\")\n",
    "        print(\"🔍 Autograd graph saved as 'glacier_inversion_graph.pdf'.\")\n",
    "\n",
    "        # Retain graph because checkpointing discards it otherwise\n",
    "        loss.backward(retain_graph=True)\n",
    "    else:\n",
    "        loss.backward()\n",
    "\n",
    "    # Debug gradient norms\n",
    "    for param in optimizer.param_groups[0]['params']:\n",
    "        print(f'Gradient of parameters: {torch.norm(param.grad)}') \n",
    "\n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_([precip_tensor, T_ma_lowest, T_mj_lowest], max_norm=100)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log timing\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Iteration {i + 1} took {elapsed_time:.2f} seconds. precip mean = {precip_tensor.mean().item():.3f}\")\n",
    "\n",
    "    # Store history\n",
    "    total_loss_history.append(loss.item())\n",
    "    total_gradients_history.append(torch.norm(precip_tensor.grad).item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        data_fidelity = torch.mean((H_simulated - observed_thk) ** 2).item()\n",
    "        data_fidelity_history.append(data_fidelity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(precip_tensor,\"percip.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_mj_lowest,T_ma_lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2560 MB.\n",
      "Peak GPU memory used: 2171.31 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()\n",
    "print_peak_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gradient_evolution(total_gradients_history,'kot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history,'kot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tensors to NumPy arrays for plotting\n",
    "Z_ELA_np = precip_tensor.to(torch.float32).detach().cpu().numpy()\n",
    "H_ice_np = H_simulated.to(torch.float32).detach().cpu().numpy()\n",
    "observed_thk_np = observed_thk.to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "# Create a figure with three subplots side by side\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize for better layout\n",
    "\n",
    "# Plot the ELA field\n",
    "im1 = ax[0].imshow(observed_thk_np-H_ice_np, origin='lower')\n",
    "fig.colorbar(im1, ax=ax[0], orientation='vertical', label='Elevation (m)')\n",
    "ax[0].set_title('Reconstructed ELA Field')\n",
    "ax[0].set_xlabel('Distance, km')\n",
    "ax[0].set_ylabel('Distance, km')\n",
    "\n",
    "# Second subplot: Ice thickness (simulated)\n",
    "im2 = ax[1].imshow( H_ice_np, cmap='jet', origin='lower')\n",
    "fig.colorbar(im2, ax=ax[1], orientation='vertical', label='Ice Thickness (m)')\n",
    "ax[1].set_title('Simulated Ice Thickness')\n",
    "ax[1].set_xlabel('Distance, km')\n",
    "\n",
    "# Third subplot: Observed ice thickness\n",
    "im3 = ax[2].imshow(observed_thk_np, cmap='jet', origin='lower')\n",
    "fig.colorbar(im3, ax=ax[2], orientation='vertical', label='Ice Thickness (m)')\n",
    "ax[2].set_title('Observed Ice Thickness')\n",
    "ax[2].set_xlabel('Distance, km')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tensors to NumPy arrays for plotting\n",
    "Precipitation = precip_tensor.to(torch.float32).detach().cpu().numpy()\n",
    "mean_anual_T,mean_June_T= apply_lapse_rate(Z_topo+H_simulated, T_ma_lowest, T_mj_lowest)\n",
    "\n",
    "# Create a figure with three subplots side by side\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 5))  # Adjust figsize for better layout\n",
    "\n",
    "# Plot the ELA field\n",
    "im1 = ax[0].imshow(Z_ELA_np[0], cmap='terrain', origin='lower')\n",
    "fig.colorbar(im1, ax=ax[0], orientation='vertical', label='[m/year]')\n",
    "ax[0].set_title('Reconstructed Precipitation Field')\n",
    "ax[0].set_xlabel('Distance, km')\n",
    "ax[0].set_ylabel('Distance, km')\n",
    "\n",
    "# Second subplot: Ice thickness (simulated)\n",
    "im2 = ax[1].imshow(mean_anual_T.detach().cpu().numpy(), cmap='jet', origin='lower')\n",
    "fig.colorbar(im2, ax=ax[1], orientation='vertical', label='[degree C]')\n",
    "ax[1].set_title('Mean Anual Temperature')\n",
    "ax[1].set_xlabel('Distance, km')\n",
    "\n",
    "# Third subplot: Observed ice thickness\n",
    "im3 = ax[2].imshow(mean_June_T.detach().cpu().numpy(), cmap='jet', origin='lower')\n",
    "fig.colorbar(im3, ax=ax[2], orientation='vertical', label='[degree C]')\n",
    "ax[2].set_title('Mean Temperature in June.')\n",
    "ax[2].set_xlabel('Distance, km')\n",
    "\n",
    "# Add a main title\n",
    "fig.suptitle('Paleo climate reconstruction', fontsize=16)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tensors to NumPy arrays for plotting\n",
    "Precipitation = precip_tensor.to(torch.float32).detach().cpu().numpy()\n",
    "Z_ELA_np = Precipitation[0]\n",
    "H_ice_np = H_simulated.to(torch.float32).detach().cpu().numpy()\n",
    "observed_thk_np = observed_thk.to(torch.float32).detach().cpu().numpy()\n",
    "mean_anual_T, mean_June_T = apply_lapse_rate(Z_topo + H_simulated, T_ma_lowest, T_mj_lowest)\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns of subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 10))\n",
    "\n",
    "# --- Top Row ---\n",
    "# Reconstructed Precipitation\n",
    "im0 = axs[0, 0].imshow(Z_ELA_np, cmap='terrain', origin='lower')\n",
    "fig.colorbar(im0, ax=axs[0, 0], orientation='vertical', label='[m/year]')\n",
    "axs[0, 0].set_title('Reconstructed Precipitation Field')\n",
    "axs[0, 0].set_xlabel('')\n",
    "axs[0, 0].set_ylabel('Distance, km')\n",
    "\n",
    "# Simulated Ice Thickness\n",
    "im1 = axs[0, 1].imshow(H_ice_np, cmap='jet', origin='lower')\n",
    "fig.colorbar(im1, ax=axs[0, 1], orientation='vertical', label='Ice Thickness [m]')\n",
    "axs[0, 1].set_title('Simulated Ice Thickness')\n",
    "axs[0, 1].set_xlabel('')\n",
    "# Remove y-axis for top-right panel\n",
    "axs[0, 1].set_ylabel('')\n",
    "axs[0, 1].set_yticklabels([])\n",
    "\n",
    "# --- Bottom Row ---\n",
    "# Mean Annual Temperature\n",
    "im2 = axs[1, 0].imshow(mean_anual_T.detach().cpu().numpy(), cmap='jet', origin='lower')\n",
    "fig.colorbar(im2, ax=axs[1, 0], orientation='vertical', label='[°C]')\n",
    "axs[1, 0].set_title('Mean Annual Temperature')\n",
    "axs[1, 0].set_xlabel('Distance, km')\n",
    "axs[1, 0].set_ylabel('Distance, km')\n",
    "\n",
    "# Thickness Difference (Observed - Simulated)\n",
    "im3 = axs[1, 1].imshow(observed_thk_np - H_ice_np, cmap='coolwarm', origin='lower')\n",
    "fig.colorbar(im3, ax=axs[1, 1], orientation='vertical', label='Difference [m]')\n",
    "axs[1, 1].set_title('Thickness Difference (Obs - Simul)')\n",
    "axs[1, 1].set_xlabel('Distance, km')\n",
    "# Remove y-axis for bottom-right panel\n",
    "axs[1, 1].set_ylabel('')\n",
    "axs[1, 1].set_yticklabels([])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

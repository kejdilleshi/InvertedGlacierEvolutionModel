{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import the necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from perlin_noise import PerlinNoise\n",
    "import netCDF4\n",
    "from IPython.display import clear_output\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def print_peak_gpu_memory():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  # in MB\n",
    "    print(f\"Peak GPU memory used: {peak_memory:.2f} MB.\")\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset after printing\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()  # Initialize NVML\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)  # Get memory info\n",
    "    print(f\"GPU memory occupied: {info.used // 1024**2} MB.\")\n",
    "\n",
    "# Function to create a 2D smooth random ELA field\n",
    "def generate_and_plot_ELA_field(Z_topo, Z_ELA, ELA_range=200, octaves=4, seed=42, device='cpu'):\n",
    "    # Get the dimensions of Z_topo\n",
    "    height, width = Z_topo.shape\n",
    "\n",
    "    # Initialize Perlin noise\n",
    "    noise = PerlinNoise(octaves=octaves, seed=seed)\n",
    "\n",
    "    # Generate a 2D noise field\n",
    "    noise_field = torch.tensor(\n",
    "        [[noise([i / height, j / width]) for j in range(width)] for i in range(height)],\n",
    "        dtype=torch.bfloat16, device=device\n",
    "    )\n",
    "\n",
    "    # Normalize the noise field to be between -1 and 1\n",
    "    min_noise = torch.min(noise_field)\n",
    "    max_noise = torch.max(noise_field)\n",
    "    normalized_noise = 2 * (noise_field - min_noise) / (max_noise - min_noise) - 1\n",
    "\n",
    "    # Scale the noise to the range [Z_ELA - ELA_range, Z_ELA + ELA_range]\n",
    "    ELA_field = Z_ELA + ELA_range * normalized_noise\n",
    "\n",
    "    return ELA_field\n",
    "def visualize(Z_surf, time, H_ice, Lx, Ly):\n",
    "    clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "    plt.figure(2, figsize=(11, 4), dpi=200)\n",
    "\n",
    "    # Convert tensors to float32 for NumPy compatibility\n",
    "    Z_surf_np = Z_surf.to(torch.float32).cpu().numpy()\n",
    "    H_ice_np = H_ice.to(torch.float32).cpu().numpy()\n",
    "\n",
    "    # First subplot: Ice surface\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(Z_surf_np, extent=[0, Lx / 1000, 0, Ly / 1000], cmap='terrain', origin='lower')\n",
    "    plt.colorbar(label='Elevation (m)')\n",
    "    plt.title('Ice Surface at ' + str(int(time)) + ' y')\n",
    "    plt.xlabel('Distance, km')\n",
    "    plt.ylabel('Distance, km')\n",
    "\n",
    "    # Second subplot: Ice thickness\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.where(H_ice_np > 0, H_ice_np, np.nan), extent=[0, Lx / 1000, 0, Ly / 1000], cmap='jet', origin='lower')\n",
    "    plt.colorbar(label='Ice Thickness (m)')\n",
    "    plt.title('Ice Thickness at ' + str(int(time)) + ' y')\n",
    "    plt.xlabel('Distance, km')\n",
    "    plt.ylabel('Distance, km')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Prepare hooks for tensors \n",
    "def print_hook_b(grad):\n",
    "    print(\"\\n db/dELA:\", torch.mean(grad))\n",
    "    return grad\n",
    "\n",
    "def reduce_hook(grad):\n",
    "    return grad * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = netCDF4.Dataset('bedrock.nc')\n",
    "Z_topo = torch.tensor(nc_file.variables['topg'][:], device=device, dtype=torch.bfloat16)\n",
    "ttot = 850  # Time limit (yr)\n",
    "grad_b = torch.tensor(0.001, dtype=torch.bfloat16, device=device)  # Mass balance gradient\n",
    "b_max = torch.tensor(0.5, dtype=torch.bfloat16, device=device)  # Maximum precip (m/yr)\n",
    "Z_ELA = torch.tensor(2000.0, dtype=torch.bfloat16, device=device)  # Elevation of equilibrium line altitude (m)\n",
    "\n",
    "# Generate and plot the ELA field\n",
    "# Z_ELA = generate_and_plot_ELA_field(Z_topo, ELA, device=device)\n",
    "rho, g, fd = torch.tensor([910.0, 9.81, 1e-18], dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA, rho=rho, g=g, fd=fd, Lx=902000, Ly=602000, dx=2000, dy=2000, dtmax=1, device=device):\n",
    "    \"\"\"\n",
    "    Solve the glacier dynamics using a diffusion-based solver with PyTorch.\n",
    "    \"\"\"\n",
    "    nx = int(Lx / dx)\n",
    "    ny = int(Ly / dy)\n",
    "    \n",
    "    epsilon = torch.tensor(1.e-20, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "    # Initialize ice thickness and surface\n",
    "    H_ice = torch.zeros((ny, nx), device=device, dtype=torch.float32)\n",
    "    Z_surf = Z_topo + H_ice\n",
    "\n",
    "    time = torch.tensor(0., dtype=torch.float32, device=device) \n",
    "    dt = torch.tensor(dtmax, dtype=torch.bfloat16, device=device)\n",
    "    it=0\n",
    "\n",
    "    while time < ttot:\n",
    "\n",
    "        time += dt\n",
    "        it += 1\n",
    "        # Compute H_avg\n",
    "        H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "  \n",
    "\n",
    "        # Compute Snorm\n",
    "        Sx = (Z_surf[:, 1:] - Z_surf[:, :-1]) / dx\n",
    "        Sy = (Z_surf[1:, :] - Z_surf[:-1, :]) / dy\n",
    "        Sx = 0.5 * (Sx[:-1, :] + Sx[1:, :])\n",
    "        Sy = 0.5 * (Sy[:, :-1] + Sy[:, 1:])\n",
    "        Snorm = torch.sqrt(Sx**2 + Sy**2 +epsilon)\n",
    "\n",
    "        # Compute diffusivity\n",
    "        # Perform high-precision computation for stability\n",
    "\n",
    "\n",
    "        D = fd * (rho * g)**3.0 * H_avg**5 * Snorm**2 + epsilon\n",
    "        # Compute adaptive time step\n",
    "        dt = min(min(dx, dy)**2 / (2.7 * torch.max(D).item()), dtmax)\n",
    "\n",
    "\n",
    "        # Compute fluxes\n",
    "        qx = -(0.5 * (D[:-1, :] + D[1:, :])) * (Z_surf[1:-1, 1:] - Z_surf[1:-1, :-1]) / dx\n",
    "        qy = -(0.5 * (D[:, :-1] + D[:, 1:])) * (Z_surf[1:, 1:-1] - Z_surf[:-1, 1:-1]) / dy\n",
    "\n",
    "        # Compute thickness change rate\n",
    "        dHdt = -(torch.diff(qx, dim=1) / dx + torch.diff(qy, dim=0) / dy)\n",
    "\n",
    "        # Update ice thickness\n",
    "        H_ice[1:-1, 1:-1] += dt * dHdt\n",
    "\n",
    "        # Compute surface mass balance (SMB)\n",
    "        b = torch.minimum(grad_b * (Z_surf - Z_ELA), b_max)\n",
    "        # b.retain_grad()\n",
    "        # b.register_hook(reduce_hook)\n",
    "\n",
    "        H_ice[1:-1, 1:-1] += dt * b[1:-1, 1:-1]\n",
    "\n",
    "        # Ensure ice thickness remains positive\n",
    "        H_ice = torch.maximum(H_ice, torch.tensor(0.0, dtype=torch.float32, device=device))\n",
    "\n",
    "        # Update surface topography\n",
    "        Z_surf = Z_topo + H_ice\n",
    "     \n",
    "\n",
    "        # Visualization at specified intervals\n",
    "        if it % 100 == 0:\n",
    "            visualize(Z_surf,time,H_ice,Lx,Ly)\n",
    "   \n",
    "\n",
    "    return H_ice , it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Z_ELA = torch.full(Z_topo.shape,2000., requires_grad=True, device=device)\n",
    "h,it=solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA)\n",
    "torch.save(h,'Obs_2D.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_32=torch.load('Obs_2D.pt', weights_only=True).to(device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time =0\n",
    "Lx=49700\n",
    "Ly=32300\n",
    "thicknes=h_32\n",
    "Z_surf=Z_topo + thicknes\n",
    "visualize(Z_surf,time,thicknes,Lx,Ly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the starting point in tracking maximum GPU memory occupied by tensors in bytes for a given device.\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Initial guesses for inversion problem\n",
    "Z_ELA = torch.full(Z_topo.shape, 2200.0, requires_grad=True, device=device)\n",
    "\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk = torch.load('Obs_2D.pt', weights_only=True).to(device,dtype=torch.float16)\n",
    "\n",
    "# Define initial and final learning rates\n",
    "initial_lr = 7\n",
    "final_lr = 5\n",
    "reg_lambda=0.000005\n",
    "n_iterations = 3\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam([Z_ELA], lr=initial_lr)\n",
    "\n",
    "# Initialize lists to track loss components\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "total_gradients_history=[]\n",
    "for i in range(n_iterations):\n",
    "    # Update the learning rate\n",
    "    lr = initial_lr - (i / (n_iterations - 1)) * (initial_lr - final_lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "    # Perform forward simulation\n",
    "    H_simulated, it= solve_glacier_dynamics(Z_topo, ttot, grad_b, b_max, Z_ELA)\n",
    "    print(it)\n",
    "    # Compute data fidelity term\n",
    "    data_fidelity = torch.mean((H_simulated - observed_thk) ** 2)\n",
    "\n",
    "    # Compute smoothness regularization\n",
    "    smoothness_x = torch.sum((Z_ELA[:, 1:] - Z_ELA[:, :-1]) ** 2)\n",
    "    smoothness_y = torch.sum((Z_ELA[1:, :] - Z_ELA[:-1, :]) ** 2)\n",
    "    smoothness_reg = smoothness_x + smoothness_y\n",
    "\n",
    "    # Total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "\n",
    "    # Backpropagate loss and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store the gradients and ELA evolution\n",
    "    total_gradients_history.append(torch.max(Z_ELA.grad).item())\n",
    "    # Store loss components for plotting later\n",
    "    total_loss_history.append(loss.item())\n",
    "    data_fidelity_history.append(data_fidelity.item())\n",
    "    regularization_history.append((reg_lambda * smoothness_reg).item())\n",
    "\n",
    "    # Print loss and gradients every 50 iterations\n",
    "    if (i + 1) % 1 == 0:\n",
    "        print(f\"\\nIteration {i+1}/{n_iterations}, Loss: {loss:.3f}, ELA: {torch.mean(Z_ELA).item():.1f}\")\n",
    "        print_gpu_utilization()\n",
    "        print_peak_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(ELA_evolution,label=\"evolution of ELA\",color='b')\n",
    "plt.plot(total_gradients_history, label='Evolution of gradients')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the loss function components\n",
    "def plot_loss_components(total_loss_history, data_fidelity_history, regularization_history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the total loss, data fidelity, and regularization term\n",
    "    plt.plot(total_loss_history, label='Total Loss', color='b', linewidth=2)\n",
    "    plt.plot(data_fidelity_history, label='Data Fidelity', color='g', linestyle='--', linewidth=2)\n",
    "    plt.plot(regularization_history, label='Regularization (Smoothness)', color='r', linestyle='-.', linewidth=2)\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.title('Loss Function Components Over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ELA field\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Convert Z_ELA to float32 for compatibility with NumPy\n",
    "Z_ELA_np = Z_ELA.to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "# Plot the field\n",
    "plt.imshow(Z_ELA_np, cmap='viridis', origin='lower')\n",
    "plt.colorbar(label='ELA (m)')\n",
    "plt.title('Reconstructed ELA Field')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class GlacierDynamicsCheckpointed(torch.nn.Module):\n",
    "    def __init__(self, Z_topo, ttot, grad_b, b_max, rho, g, fd, Lx, Ly, dx, dy, dtmax, device):\n",
    "        super().__init__()\n",
    "        self.Z_topo = Z_topo\n",
    "        self.ttot = ttot\n",
    "        self.grad_b = grad_b\n",
    "        self.b_max = b_max\n",
    "        self.rho = rho\n",
    "        self.g = g\n",
    "        self.fd = fd\n",
    "        self.Lx = Lx\n",
    "        self.Ly = Ly\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "        self.dtmax = dtmax\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, Z_ELA):\n",
    "        return self.solve_glacier_dynamics(self.Z_topo, self.ttot, self.grad_b, self.b_max, Z_ELA)\n",
    "\n",
    "    def solve_glacier_dynamics(self, Z_topo, ttot, grad_b, b_max, Z_ELA):\n",
    "        nx = int(self.Lx / self.dx)\n",
    "        ny = int(self.Ly / self.dy)\n",
    "\n",
    "        epsilon = torch.tensor(1.e-20, dtype=torch.bfloat16, device=self.device)\n",
    "        H_ice = torch.zeros((ny, nx), device=self.device, dtype=torch.float32)\n",
    "        Z_surf = Z_topo + H_ice\n",
    "\n",
    "        time = torch.tensor(0., dtype=torch.float32, device=self.device)\n",
    "        dt = torch.tensor(self.dtmax, dtype=torch.bfloat16, device=self.device)\n",
    "        it = 0\n",
    "\n",
    "        def checkpointed_step(H_ice, Z_surf, Z_ELA, time):\n",
    "            # Compute H_avg\n",
    "            H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "\n",
    "            # Compute Snorm\n",
    "            Sx = (Z_surf[:, 1:] - Z_surf[:, :-1]) / self.dx\n",
    "            Sy = (Z_surf[1:, :] - Z_surf[:-1, :]) / self.dy\n",
    "            Sx = 0.5 * (Sx[:-1, :] + Sx[1:, :])\n",
    "            Sy = 0.5 * (Sy[:, :-1] + Sy[:, 1:])\n",
    "            Snorm = torch.sqrt(Sx**2 + Sy**2 + epsilon)\n",
    "\n",
    "            # Compute diffusivity\n",
    "            D = self.fd * (self.rho * self.g)**3.0 * H_avg**5 * Snorm**2 + epsilon\n",
    "\n",
    "            # Compute adaptive time step\n",
    "            dt = min(min(self.dx, self.dy)**2 / (2.7 * torch.max(D).item()), self.dtmax)\n",
    "\n",
    "            # Compute fluxes\n",
    "            qx = -(0.5 * (D[:-1, :] + D[1:, :])) * (Z_surf[1:-1, 1:] - Z_surf[1:-1, :-1]) / self.dx\n",
    "            qy = -(0.5 * (D[:, :-1] + D[:, 1:])) * (Z_surf[1:, 1:-1] - Z_surf[:-1, 1:-1]) / self.dy\n",
    "\n",
    "            # Compute thickness change rate\n",
    "            dHdt = -(torch.diff(qx, dim=1) / self.dx + torch.diff(qy, dim=0) / self.dy)\n",
    "\n",
    "            # Update ice thickness\n",
    "            H_ice = H_ice.clone()\n",
    "            H_ice[1:-1, 1:-1] = H_ice[1:-1, 1:-1] + dt * dHdt\n",
    "\n",
    "\n",
    "            # Compute surface mass balance (SMB)\n",
    "            b = torch.minimum(grad_b * (Z_surf - Z_ELA), b_max)\n",
    "            # b.retain_grad()\n",
    "            # b.register_hook(reduce_hook)\n",
    "            H_ice = H_ice.clone()\n",
    "            H_ice[1:-1, 1:-1] = H_ice[1:-1, 1:-1] + dt * b[1:-1, 1:-1]\n",
    "\n",
    "            # Ensure ice thickness remains positive\n",
    "            H_ice = torch.maximum(H_ice, torch.tensor(0.0, dtype=torch.float32, device=self.device))\n",
    "\n",
    "            # Update surface topography\n",
    "            Z_surf = Z_topo + H_ice\n",
    "            return H_ice, Z_surf, time + dt\n",
    "\n",
    "        while time < ttot:\n",
    "            H_ice, Z_surf, time = checkpoint(checkpointed_step, H_ice, Z_surf, Z_ELA, time)\n",
    "            it += 1\n",
    "        \n",
    "        return H_ice, it\n",
    "\n",
    "# Wrap the solve_glacier_dynamics function in the checkpointed module\n",
    "glacier_model = GlacierDynamicsCheckpointed(Z_topo, ttot, grad_b, b_max, rho, g, fd, 902000, 602000, 2000, 2000, 1, device)\n",
    "\n",
    "# Replace the direct call with a call to the checkpointed model\n",
    "# H_simulated, it = glacier_model(Z_ELA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for the forward computation to use with checkpointing\n",
    "def checkpointed_forward(Z_ELA,observed_thk, reg_lambda):\n",
    "    # Perform forward simulation\n",
    "    H_simulated, it = glacier_model(Z_ELA)  # Use the checkpointed glacier model\n",
    "    # print('Nb steps: ',it)\n",
    "\n",
    "    # Compute data fidelity term\n",
    "    data_fidelity = torch.mean((H_simulated - observed_thk) ** 2)\n",
    "\n",
    "    # Compute smoothness regularization\n",
    "    smoothness_x = torch.sum((Z_ELA[:, 1:] - Z_ELA[:, :-1]) ** 2)\n",
    "    smoothness_y = torch.sum((Z_ELA[1:, :] - Z_ELA[:-1, :]) ** 2)\n",
    "    smoothness_reg = smoothness_x + smoothness_y\n",
    "\n",
    "    # Total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "    return loss,H_simulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb iterations:  1\n",
      "Nb iterations:  2\n",
      "Nb iterations:  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset the starting point in tracking maximum GPU memory occupied by tensors in bytes for a given device.\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Initial guesses for inversion problem\n",
    "Z_ELA = torch.full(Z_topo.shape, 2200.0, requires_grad=True, device=device)\n",
    "\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk = torch.load('Obs_2D.pt', weights_only=True).to(device,dtype=torch.float16)\n",
    "\n",
    "# Define initial and final learning rates\n",
    "initial_lr = 7\n",
    "final_lr = 5\n",
    "reg_lambda=0.00001\n",
    "n_iterations = 10\n",
    "# Optimizer setup remains unchanged\n",
    "optimizer = torch.optim.Adam([Z_ELA], lr=initial_lr)\n",
    "\n",
    "# Initialize lists to track loss components\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "total_gradients_history=[]\n",
    "\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Update the learning rate\n",
    "    lr = initial_lr - (i / (n_iterations - 1)) * (initial_lr - final_lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    print('Nb iterations: ',i+1)\n",
    "\n",
    "    # Perform forward pass with gradient checkpointing\n",
    "    loss,H_simulated = checkpoint(\n",
    "        checkpointed_forward, Z_ELA, observed_thk, reg_lambda\n",
    "    )\n",
    "    Z_ELA.register_hook(reduce_hook)\n",
    "    # Backpropagate loss and update parameters\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log the components of the loss for tracking\n",
    "    total_loss_history.append(loss.item())\n",
    "    total_gradients_history.append(torch.max(Z_ELA.grad).item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        data_fidelity = torch.mean((H_simulated - observed_thk) ** 2).item()\n",
    "        data_fidelity_history.append(data_fidelity)\n",
    "        # regularization_history.append((reg_lambda * smoothness_reg).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 11810 MB.\n",
      "Peak GPU memory used: 8862.02 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()\n",
    "print_peak_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(ELA_evolution,label=\"evolution of ELA\",color='b')\n",
    "plt.plot(total_gradients_history, label='Evolution of gradients')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tensors to NumPy arrays for plotting\n",
    "Z_ELA_np = Z_ELA.to(torch.float32).detach().cpu().numpy()\n",
    "H_ice_np = H_simulated.to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))  # Adjust figsize for better layout\n",
    "\n",
    "# Plot the ELA field\n",
    "im1 = ax[0].imshow(Z_ELA_np, cmap='terrain', origin='lower')\n",
    "ax[0].set_title('Reconstructed ELA Field')\n",
    "fig.colorbar(im1, ax=ax[0], orientation='vertical', label='ELA (m)')\n",
    "\n",
    "# Second subplot: Ice thickness\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.where(H_ice_np > 0, H_ice_np, np.nan), cmap='jet', origin='lower')\n",
    "plt.colorbar(label='Ice Thickness (m)')\n",
    "plt.xlabel('Distance, km')\n",
    "plt.ylabel('Distance, km')\n",
    "# Add a main title if needed\n",
    "plt.suptitle('Glacier Evolution Analysis', fontsize=16)\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit titles and colorbars\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions \n",
    "- crop the medium from unneccessary parts\n",
    "- optimize GPU utilization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

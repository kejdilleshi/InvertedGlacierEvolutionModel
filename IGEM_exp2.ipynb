{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from time import time, sleep\n",
    "import threading\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to track GPU memory usage\n",
    "def track_gpu_utilization(interval=1):\n",
    "    memory_usage = []\n",
    "    timestamps = []\n",
    "    \n",
    "    # Define a helper function to gather GPU memory usage\n",
    "    def record_utilization():\n",
    "        while tracking:\n",
    "            mem = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert to GB\n",
    "            memory_usage.append(mem)\n",
    "            timestamps.append(time() - start_time)\n",
    "            sleep(interval)  # Wait before recording again\n",
    "\n",
    "    # Start tracking in a separate thread\n",
    "    tracking = True\n",
    "    start_time = time()\n",
    "    tracking_thread = threading.Thread(target=record_utilization)\n",
    "    tracking_thread.start()\n",
    "    \n",
    "    return memory_usage, timestamps, lambda: tracking_thread.join()\n",
    "# Visualization function\n",
    "def plot_gpu_utilization(memory_usage, timestamps):\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(timestamps, memory_usage, label='GPU Memory Usage (GB)')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Memory Usage (GB)')\n",
    "    plt.title('GPU Memory Utilization Over Time')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def print_peak_gpu_memory():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  # in MB\n",
    "    print(f\"Peak GPU memory used: {peak_memory:.2f} MB.\")\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset after printing\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()  # Initialize NVML\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)  # Get memory info\n",
    "    print(f\"GPU memory occupied: {info.used // 1024**2} MB.\")\n",
    "print_gpu_utilization()  # Print memory before starting the optimization loop\n",
    "\n",
    "# Visualization function \n",
    "def visualize_glacier(x, Z, Z_bed, z_ELA, b, Time):\n",
    "    Z_list = Z.cpu().tolist()  # Convert to list\n",
    "    Z_bed_list = Z_bed.cpu().tolist()  # Convert to list\n",
    "    x_list = x.cpu().tolist()  # Convert to list\n",
    "    b_list = b.cpu().tolist()  # Convert to list\n",
    "    clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "    \n",
    "    plt.figure(2, figsize=(7, 5), dpi=200)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_list, 'b', linewidth=2) \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_bed_list, 'k', linewidth=1)\n",
    "    plt.plot([x_list[0] / 1000, x_list[-1] / 1000], [z_ELA, z_ELA], 'g')\n",
    "    plt.ylim([min(Z_bed_list), max(Z_bed_list)])\n",
    "    plt.ylabel('Elevation, m')\n",
    "    plt.title('Glacier après ' + str(int(Time)) + ' années')\n",
    "\n",
    "    plt.subplot(2, 2, 3, aspect=20.0)\n",
    "    plt.plot([xi / 1000 for xi in x_list], b_list, 'b', linewidth=2)\n",
    "    plt.plot([x_list[0] / 1000, x_list[-1] / 1000], [0, 0], 'k', linewidth=1)\n",
    "    plt.title('Bilan de masse effectif')\n",
    "    plt.xlabel('Distance, km') \n",
    "    plt.ylabel('Bilan de masse, m/a') \n",
    "    plt.pause(0.1)\n",
    "\n",
    "    plt.show()\n",
    "def plot_ELA(z_ELA,name):    \n",
    "    z_ELA_list=z_ELA.cpu().tolist()\n",
    "    clear_output(wait=False)  # Clear the previous output in the notebook\n",
    "    # True ELA\n",
    "    ELA = 1200  # equilibrium line altitude\n",
    "    True_ELA = ELA + 200 * np.cos((t / ttot) * 2 * np.pi)\n",
    "\n",
    "    plt.figure(figsize=(7, 4), dpi=200)\n",
    "\n",
    "    plt.plot(z_ELA_list, 'b', label=\"Resulting ELA\")\n",
    "    plt.plot(True_ELA, 'g',label=\"True ELA\")\n",
    "\n",
    "    # plt.ylim([min(Z_bed_list), max(Z_bed_list)])\n",
    "    plt.ylabel('Elevation, m')\n",
    "    plt.title('Temporal ELA ')\n",
    "    plt.legend()\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "# Visualization function \n",
    "def visualize_evolution(x, Z_list, Z_bed, z_ELA,observed_thk):\n",
    "    Z_lists=[Z_list[i].cpu().tolist()  for i  in range (len(Z_list))]\n",
    "    Z_bed_list = Z_bed.cpu().tolist()  # Convert to list\n",
    "    x_list = x.cpu().tolist()  # Convert to list\n",
    "    z_ELA_list=z_ELA.cpu().tolist()\n",
    "    Z_observed=(Z_bed+observed_thk).cpu().tolist()\n",
    "\n",
    "    clear_output(wait=False)  # Clear the previous output in the notebook\n",
    "    plt.figure(figsize=(7, 4), dpi=200)\n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_lists[0], 'b', linewidth=1,linestyle='dashed',label='Evolution in time') \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_lists[1], 'b', linewidth=1,linestyle='dashed') \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_lists[2], 'b', linewidth=1,linestyle='dashed') \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_lists[3], 'b', linewidth=1,label='Last thickness') \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_observed, 'r', linewidth=1,label='Observed thickness') \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_bed_list, 'k', linewidth=1,label='ELA')\n",
    "    plt.plot([x_list[0] / 1000, x_list[-1] / 1000], [z_ELA_list, z_ELA_list], 'g')\n",
    "    plt.ylim([min(Z_bed_list), max(Z_bed_list)])\n",
    "    plt.ylabel('Elevation, m')\n",
    "    plt.title('Glacier evolution')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "def compute_slope(Z, dx):\n",
    "    # Compute the slope (gradient of surface) using finite difference\n",
    "    slope = torch.diff(Z) / dx\n",
    "    return slope\n",
    "def myround(x, base=50):\n",
    "    return base * round(x/base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare hooks for tensors \n",
    "def print_hook_b(grad):\n",
    "    print(\"\\n db/dELA:\",torch.mean(grad))\n",
    "    return grad\n",
    "def print_hook_h(grad):\n",
    "    print(\"\\n dH/db:\",torch.mean(grad))\n",
    "    return grad\n",
    "def sqrt_hook(grad):\n",
    "    if torch.abs(torch.mean(grad))>1:\n",
    "        print(grad**0.5)\n",
    "        return grad**0.5\n",
    "def reduce_hook(grad):\n",
    "    return grad*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics\n",
    "b_max = 1.0  # maximum ice balance m/yr\n",
    "grad_b = 0.001  # gradient of ice balance as a function of elevation. yr^-1\n",
    "\n",
    "\n",
    "Lx = 1.5e5  # model length, m\n",
    "ttot = 1500  # total time\n",
    "t=torch.arange(0,ttot+1,50)\n",
    "ELA = 1700  # equilibrium line altitude\n",
    "z_ELA = ELA + 200 * np.cos((t / ttot) * 2 * np.pi)\n",
    "rhog = 910 * 9.81  # ice density kg/m^3 * gravity m/s^{-2}\n",
    "fd = 1e-15  # physical constant for ice diffusivity, Pa^3/y\n",
    "kD = fd * rhog**3  # lump all constants for diffusivity together\n",
    "epsilon = 1e-12 # Epsilon to avoid division by zero\n",
    "\n",
    "\n",
    "\n",
    "# Numerics\n",
    "nx = 201  # number of cells\n",
    "dx = Lx / (nx - 1)  # number of cells \n",
    "dtmax = 1      # initial dt, will be changed within loop, yr\n",
    "dt    = dtmax  # initial dt, will be changed within loop, yr\n",
    "x = torch.linspace(0, Lx, nx, device=device)  # x-coordinates\n",
    "nout = 100  # frequency of plotting\n",
    "\n",
    "# Initialization\n",
    "Z_bed = -1000 * torch.log(x + 1000) + 11522.8  # topography\n",
    "H_initial= torch.zeros(nx, device=device) #torch.load('initial_thickness.pt', weights_only=True).to(device)\n",
    "H = H_initial.clone()\n",
    "Time = 0.0  # initialize time\n",
    "nplot = 0  # counter for plotting\n",
    "\n",
    "Z = Z_bed + H  # ice surface\n",
    "\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data for training\n",
    "data = []\n",
    "\n",
    "# Time loop\n",
    "start = time.time()\n",
    "\n",
    "# Initialize a list to store the volumes and corresponding time values\n",
    "volume_history = []\n",
    "time_history = []\n",
    "\n",
    "while Time < ttot:\n",
    "    # Get the index of time in the ELA list\n",
    "    idx = np.where(t == myround(Time))[0].item()\n",
    "\n",
    "    # Compute dHdt due to diffusion\n",
    "    H_av = 0.5 * (H[:-1] + H[1:])  # average height between cells (nx-1)\n",
    "    D = kD * H_av**5 * (torch.diff(Z) / dx)**2  # diffusivity (nx-1)\n",
    "    qx = -D * torch.diff(Z) / dx  # ice flux\n",
    "\n",
    "    dHdt = -torch.diff(qx) / dx  # change in ice thickness from flow\n",
    "\n",
    "    # Update time step as function of D\n",
    "    max_D = torch.max(D).item()\n",
    "    dt = min(dtmax, dx**2 / (2.1 * (max_D + epsilon)))  # update time step\n",
    "\n",
    "    # Update thickness of ice (iceflow)\n",
    "    H[1:-1] += dt * dHdt  # update ice thickness from flow\n",
    "\n",
    "    # Update ice thickness (mass balance)\n",
    "    b = torch.minimum(grad_b * (Z - z_ELA[idx]), torch.tensor(b_max, device=device))\n",
    "    H[1:-1] += dt * b[1:-1]\n",
    "\n",
    "    H[H < 0] = 0  # set any negative thickness to 0\n",
    "\n",
    "    # Boundary conditions\n",
    "    H[0] = 0\n",
    "    H[-1] = 0\n",
    "\n",
    "    Z = Z_bed + H  # update ice surface\n",
    "    Time += dt  # update time\n",
    "    it += 1\n",
    "\n",
    "    # Calculate the volume of the ice\n",
    "    volume = torch.sum(H * dx).item()  # Integrate H over the domain\n",
    "    volume_history.append(volume)\n",
    "    time_history.append(Time)\n",
    "\n",
    "    # Save observations\n",
    "    if round(Time) == 1000:\n",
    "        torch.save(H, 'observed_thk_1000.pt')\n",
    "\n",
    "    if round(Time) == 1250:\n",
    "        torch.save(H, 'observed_thk_1250.pt')\n",
    "        \n",
    "    if round(Time) == 1500:\n",
    "        torch.save(H, 'observed_thk_1500.pt')\n",
    "\n",
    "    # Call visualization function\n",
    "    if it % nout == 0:\n",
    "        visualize_glacier(x, Z, Z_bed, z_ELA[idx], b, Time)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Elapsed time is : {end - start} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the volume evolution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(time_history, volume_history, label=\"Ice Volume\", color='blue')\n",
    "plt.xlabel(\"Time (years)\")\n",
    "plt.ylabel(\"Ice Volume\")\n",
    "plt.title(\"Evolution of Ice Volume Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sav e the observations.\n",
    "# torch.save(H,'observed_thk_1500.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform forward simulation of glacier thickness with differentiable operations\n",
    "def forward_simulation(H_initial,b_max, grad_b,z_ELA, ttot=1e3, device=device,display_time=False):\n",
    "    start= time.time()\n",
    "    # Physics constants\n",
    "    n=3\n",
    "    rhog = 910 * 9.81  # ice density kg/m^3 * gravity m/s^{-2}\n",
    "    fd = 1e-15  # physical constant for ice diffusivity, Pa^3/y\n",
    "    kD = fd * rhog**n  # lump all constants for diffusivity together\n",
    "    epsilon = 1e-12\n",
    "\n",
    "    # Numerics\n",
    "    Lx = 1.5e5  # model length, m\n",
    "    nx = 201  # number of cells\n",
    "    dx = Lx / (nx - 1)  # number of cells \n",
    "    dtmax = 1      # initial dt, will be changed within loop, yr\n",
    "    dt    = dtmax  # initial dt, will be changed within loop, yr\n",
    "    Time = 0\n",
    "\n",
    "    # Initialization\n",
    "    x = torch.linspace(0, Lx, nx, device=device)  # x-coordinates\n",
    "    Z_bed = -1000 * torch.log(x + 1000) + 11522.8  # topography (avoid log(0))\n",
    "    H = H_initial.clone()  # initial ice thickness\n",
    "    Z = Z_bed + H  # ice surface\n",
    "\n",
    "    recorded_1100 = False\n",
    "    recorded_1350 = False\n",
    "\n",
    "    while Time < ttot:\n",
    "        #get the index of time in the ELA list\n",
    "        idx=np.where(t == myround(Time))[0].item()\n",
    "        # compute dHdt due to diffusion\n",
    "        H_av = 0.5 * (H[:-1] + H[1:])  # average height between cells (nx-1)\n",
    "        D = kD * H_av**5 * (torch.diff(Z) / dx)**(n-1)  # diffusivity (nx-1)\n",
    "        qx = -D * torch.diff(Z) / dx  # ice flux\n",
    "        # Compute velocity safely\n",
    "        dHdt = -torch.diff(qx) / dx  # change in ice thickness from flow\n",
    "        \n",
    "        # update time step as function of D\n",
    "        max_D = torch.max(D).item()\n",
    "        dt = min(dtmax, dx**2 / (2.1 * (max_D + epsilon)))  # update time step\n",
    "\n",
    "        # update thickness of ice (iceflow)\n",
    "        H[1:-1] += dt * dHdt  # update ice thickness from flow\n",
    "    \n",
    "        # update ice thickness (mass balance)\n",
    "        b = torch.minimum(grad_b * (Z - z_ELA[idx]), torch.tensor(b_max, device=device)) \n",
    "        b.retain_grad() \n",
    "        b.register_hook(reduce_hook)\n",
    "        \n",
    "        H[1:-1] += dt * b[1:-1]\n",
    "        H.retain_grad()\n",
    "        H.register_hook(reduce_hook)\n",
    "        H[H < 0] = 0  # set any negative thickness to 0\n",
    "    \n",
    "        # Boundary conditions\n",
    "        H[0] = 0\n",
    "        H[-1] = 0\n",
    "    \n",
    "        Z = Z_bed + H  # update ice surface\n",
    "        Time += dt  # update time# Call visualization function\n",
    "\n",
    "        # Save observations\n",
    "        if not recorded_1100 and round(Time)== 1000:\n",
    "            H_simulated1 = H.clone()\n",
    "            recorded_1100= True\n",
    "\n",
    "        if  not recorded_1350 and round(Time)== 1250:\n",
    "            H_simulated2 = H.clone()\n",
    "            recorded_1350=True\n",
    "\n",
    "    H_simulated3 = H.clone()\n",
    "\n",
    "    return H_simulated1, H_simulated2, H_simulated3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guesses for inversion problem\n",
    "b_max = 1.0\n",
    "grad_b = 0.001\n",
    "z_ELA = 1000 + 200 * torch.cos((t / ttot) * 2 * torch.pi)\n",
    "z_ELA.requires_grad_(True)\n",
    "# z_ELA = torch.full((len(t),),1200., requires_grad=True, device=device)\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk1 = torch.load('observed_thk_1000.pt', weights_only=True).to(device) # Ensure it's on the right device\n",
    "observed_thk2 = torch.load('observed_thk_1250.pt', weights_only=True).to(device) # Ensure it's on the right device\n",
    "observed_thk3 = torch.load('observed_thk_1500.pt', weights_only=True).to(device) # Ensure it's on the right device\n",
    "\n",
    "\n",
    "# Define initial and final learning rates\n",
    "initial_lr = 7\n",
    "final_lr = 7\n",
    "n_iterations = 60\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam([z_ELA], lr=initial_lr)\n",
    "reg_lambda=0.001\n",
    "\n",
    "# Initialize lists to track loss components\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "total_gradients_history=[]\n",
    "ELA_evolution=[]\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Update the learning rate\n",
    "    lr = initial_lr - (i / (n_iterations - 1)) * (initial_lr - final_lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    \n",
    "    # Perform forward simulation\n",
    "    H_simulated1,H_simulated2,H_simulated3 = forward_simulation(H_initial,b_max, grad_b, z_ELA,ttot=ttot,display_time=False)\n",
    "    \n",
    "    # Compute data fidelity and regularization\n",
    "    data_fidelity1 = torch.mean((H_simulated1 - observed_thk1) ** 2)\n",
    "    data_fidelity2 = torch.mean((H_simulated2 - observed_thk2) ** 2)\n",
    "    data_fidelity3 = torch.mean((H_simulated3 - observed_thk3) ** 2)\n",
    "\n",
    "    smoothness_reg = torch.sum((z_ELA[1:] - z_ELA[:-1]) ** 2)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = data_fidelity1 + data_fidelity2 + 1.5* data_fidelity3 + reg_lambda * smoothness_reg\n",
    "    # Backpropagate loss and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    total_gradients_history.append(torch.mean(z_ELA.grad).cpu())\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # Store loss components for plotting later\n",
    "    total_loss_history.append(loss.item())\n",
    "    data_fidelity_history.append(data_fidelity3.item())\n",
    "    regularization_history.append((reg_lambda * smoothness_reg).item())\n",
    "\n",
    "    # Print loss, gradients and current parameters every 50 iterations \n",
    "\n",
    "    if (i + 1) % 20 == 0:\n",
    "        plot_ELA(z_ELA,str(i))\n",
    "\n",
    "        print(f\"\\nIteration {i+1}/{n_iterations}, Loss: {loss:.3f} \")\n",
    "        print(f\"Gradient of ELA : {torch.mean(z_ELA.grad)} ELA is {torch.mean(z_ELA)} m\")\n",
    "\n",
    "print_gpu_utilization()  # Print memory after the loop\n",
    "print_peak_gpu_memory()  # Print the peak memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(ELA_evolution,label=\"evolution of ELA\",color='b')\n",
    "plt.plot(total_gradients_history, label='Evolution of gradients')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the ELA\n",
    "plot_ELA(z_ELA,'Final_ELA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the loss function components\n",
    "def plot_loss_components(total_loss_history, data_fidelity_history, regularization_history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the total loss, data fidelity, and regularization term\n",
    "    plt.plot(total_loss_history, label='Total Loss', color='b', linewidth=2)\n",
    "    plt.plot(data_fidelity_history, label='Data Fidelity', color='g', linestyle='--', linewidth=2)\n",
    "    plt.plot(regularization_history, label='Regularization (Smoothness)', color='r', linestyle='-.', linewidth=2)\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.title('Loss Function Components Over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the optimization loop\n",
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

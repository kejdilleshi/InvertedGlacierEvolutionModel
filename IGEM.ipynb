{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics\n",
    "b_max = 0.3  # maximum ice balance m/yr\n",
    "grad_b = 0.001  # gradient of ice balance as a function of elevation. yr^-1\n",
    "\n",
    "z_ELA = 1200  # equilibrium line altitude\n",
    "Lx = 1e5  # model length, m\n",
    "ttot = 3e3  # total time\n",
    "rhog = 910 * 9.81  # ice density kg/m^3 * gravity m/s^{-2}\n",
    "fd = 1e-15  # physical constant for ice diffusivity, Pa^3/y\n",
    "kD = fd * rhog**3  # lump all constants for diffusivity together\n",
    "\n",
    "# Numerics\n",
    "nx = 201  # number of cells\n",
    "dx = Lx / (nx - 1)  # number of cells \n",
    "dtmax = 1      # initial dt, will be changed within loop, yr\n",
    "dt    = dtmax  # initial dt, will be changed within loop, yr\n",
    "x = torch.linspace(0, Lx, nx, device=device)  # x-coordinates\n",
    "nout = 500  # frequency of plotting\n",
    "\n",
    "# Initialization\n",
    "Z_bed = -1000 * torch.log(x + 1000) + 11522.8  # topography\n",
    "H = torch.zeros(nx, device=device)  # ice thickness\n",
    "time = 0.0  # initialize time\n",
    "nplot = 0  # counter for plotting\n",
    "\n",
    "Z = Z_bed + H  # ice surface\n",
    "\n",
    "time = 0\n",
    "it = 0\n",
    "# Epsilon to avoid division by zero\n",
    "epsilon = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function using tolist()\n",
    "def visualize_glacier(x, Z, Z_bed, z_ELA, b, time):\n",
    "    Z_list = Z.cpu().tolist()  # Convert to list\n",
    "    Z_bed_list = Z_bed.cpu().tolist()  # Convert to list\n",
    "    x_list = x.cpu().tolist()  # Convert to list\n",
    "    b_list = b.cpu().tolist()  # Convert to list\n",
    "    clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "    \n",
    "    plt.figure(2, figsize=(7, 5), dpi=200)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_list, 'b', linewidth=2) \n",
    "    plt.plot([xi / 1000 for xi in x_list], Z_bed_list, 'k', linewidth=1)\n",
    "    plt.plot([x_list[0] / 1000, x_list[-1] / 1000], [z_ELA, z_ELA], 'g')\n",
    "    plt.ylim([min(Z_bed_list), max(Z_bed_list)])\n",
    "    plt.ylabel('Elevation, m')\n",
    "    plt.title('Glacier après ' + str(int(time)) + ' années')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot([min(grad_b * (zi - z_ELA), b_max) for zi in Z_list], Z_list, '--k', linewidth=2)\n",
    "    plt.plot([min(b_list), b_max + 0.3], [z_ELA, z_ELA], 'g')\n",
    "    plt.plot([0, 0], [min(Z_bed_list), max(Z_bed_list)], 'k', linewidth=1)\n",
    "    plt.ylim([min(Z_bed_list), max(Z_bed_list)])\n",
    "    plt.title('Fonction bilan de masse') \n",
    "    plt.xlabel('Bilan de masse, m/a')  \n",
    "\n",
    "    plt.subplot(2, 2, 3, aspect=20.0)\n",
    "    plt.plot([xi / 1000 for xi in x_list], b_list, 'b', linewidth=2)\n",
    "    plt.plot([x_list[0] / 1000, x_list[-1] / 1000], [0, 0], 'k', linewidth=1)\n",
    "    plt.title('Bilan de masse effectif')\n",
    "    plt.xlabel('Distance, km') \n",
    "    plt.ylabel('Bilan de masse, m/a') \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time loop\n",
    "while time < ttot:\n",
    "\n",
    "    # compute dHdt due to diffusion\n",
    "    H_av = 0.5 * (H[:-1] + H[1:])  # average height between cells (nx-1)\n",
    "    D = kD * H_av**5 * (torch.diff(Z) / dx)**2  # diffusivity (nx-1)\n",
    "    qx = -D * torch.diff(Z) / dx  # ice flux\n",
    "    dHdt = -torch.diff(qx) / dx  # change in ice thickness from flow\n",
    "\n",
    "    # update time step as function of D\n",
    "    max_D = torch.max(D).item()\n",
    "    dt = min(dtmax, dx**2 / (2.1 * (max_D + epsilon)))  # update time step (added epsilon to avoid division by zero)\n",
    "\n",
    "    # update thickness of ice (iceflow)\n",
    "    H[1:-1] += dt * dHdt  # update ice thickness from flow\n",
    "\n",
    "    # update ice thickness (mass balance)\n",
    "    b = torch.minimum(grad_b * (Z - z_ELA), torch.tensor(b_max, device=device)) \n",
    "    H[1:-1] += dt * b[1:-1] \n",
    "\n",
    "    H[H < 0] = 0  # set any negative thickness to 0\n",
    "\n",
    "    # Boundary conditions\n",
    "    H[0] = 0\n",
    "    H[-1] = 0\n",
    "\n",
    "    Z = Z_bed + H  # update ice surface\n",
    "    time += dt  # update time\n",
    "\n",
    "    it += 1\n",
    "\n",
    "    # Call visualization function\n",
    "    if it % nout == 0:\n",
    "\n",
    "        visualize_glacier(x, Z, Z_bed, z_ELA, b, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sav e the observations.\n",
    "# torch.save(H,'observed_thk.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small epsilon to avoid division by zero or log of zero\n",
    "epsilon = 1e-8\n",
    "\n",
    "# Function to perform forward simulation of glacier thickness with differentiable operations\n",
    "def forward_simulation(b_max, grad_b, z_ELA, nx=201, Lx=1e5, ttot=3e3, dtmax=1, device='cpu'):\n",
    "    # Physics constants\n",
    "    rhog = 910 * 9.81  # ice density kg/m^3 * gravity m/s^{-2}\n",
    "    fd = 1e-15  # physical constant for ice diffusivity, Pa^3/y\n",
    "    kD = fd * rhog**3  # lump all constants for diffusivity together\n",
    "    dx = Lx / (nx - 1)  # cell size\n",
    "    \n",
    "    # Initialization\n",
    "    x = torch.linspace(0, Lx, nx, device=device)  # x-coordinates\n",
    "    Z_bed = -1000 * torch.log(x + 1000 + epsilon) + 11522.8  # topography (avoid log(0))\n",
    "    H = torch.zeros(nx, device=device)  # initial ice thickness\n",
    "    Z = Z_bed + H  # ice surface\n",
    "    \n",
    "    time = 0.0\n",
    "    while time < ttot:\n",
    "        # Compute dHdt due to diffusion\n",
    "        H_av = 0.5 * (H[:-1] + H[1:]) + epsilon  # avoid zero in averaging height\n",
    "        qx = - torch.diff(Z) / (dx + epsilon)  # ice flux\n",
    "        dHdt = -torch.diff(qx) / (dx + epsilon)  # change in ice thickness from flow\n",
    "        \n",
    "        # Update time step as function of D\n",
    "        max_D = 0.1\n",
    "        dt = min(dtmax, dx**2 / (2.1 * max_D))  # avoid division by zero\n",
    "        \n",
    "        # Use out-of-place operations to update ice thickness from flow and mass balance\n",
    "        H_new = H.clone()  # create a new tensor to avoid in-place operations\n",
    "        H_new[1:-1] += dt * dHdt  # ice thickness from flow\n",
    "        \n",
    "        # Handle minimum ice balance using a smooth approximation for differentiability\n",
    "        b = torch.tanh(grad_b * (Z - z_ELA)) * b_max  # Smooth approximation for mass balance\n",
    "        H_new[1:-1] += dt * b[1:-1]  # ice thickness from mass balance\n",
    "        \n",
    "        H_new[H_new < 0] = 0  # ensure ice thickness is non-negative\n",
    "        H_new[0] = H_new[-1] = 0  # boundary conditions\n",
    "\n",
    "        # Update ice surface\n",
    "        Z = Z_bed + H_new\n",
    "        H = H_new  # Assign updated thickness for the next iteration\n",
    "        time += dt  # update time\n",
    "        # if it % nout == 0:\n",
    "        #     visualize_glacier(x, Z, Z_bed, z_ELA, b, time)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the forward run \n",
    "forward_simulation(b_max,grad_b,z_ELA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guesses for inversion problem\n",
    "b_max = 0.3\n",
    "grad_b = 0.001\n",
    "z_ELA = torch.tensor(1000.0, requires_grad=True, device='cpu')\n",
    "\n",
    "# Observed glacier thickness (assumed already loaded as observed_thk tensor)\n",
    "observed_thk = torch.load('observed_thk.pt', weights_only=True).to('cpu') # Ensure it's on the right device\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam([z_ELA], lr=1)\n",
    "\n",
    "# Regularization weight (tune this value)\n",
    "reg_lambda = 0.1\n",
    "\n",
    "# Optimization loop\n",
    "n_iterations = 50\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to track loss components\n",
    "total_loss_history = []\n",
    "data_fidelity_history = []\n",
    "regularization_history = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    \n",
    "    # Perform forward simulation\n",
    "    H_simulated = forward_simulation(b_max, grad_b, z_ELA)\n",
    "    \n",
    "    # Compute data fidelity and regularization\n",
    "    data_fidelity = torch.mean((H_simulated - observed_thk) ** 2)\n",
    "    smoothness_reg = torch.sum((H_simulated[1:] - H_simulated[:-1]) ** 2)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = data_fidelity + reg_lambda * smoothness_reg\n",
    "    \n",
    "    # Backpropagate loss and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store loss components for plotting later\n",
    "    total_loss_history.append(loss.item())\n",
    "    data_fidelity_history.append(data_fidelity.item())\n",
    "    regularization_history.append((reg_lambda * smoothness_reg).item())\n",
    "    \n",
    "    # Print loss and current parameters every 50 iterations\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Iteration {i+1}/{n_iterations}, Loss: {loss.item()}\")\n",
    "        print(f\"z_ELA: {z_ELA.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the loss function components\n",
    "def plot_loss_components(total_loss_history, data_fidelity_history, regularization_history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the total loss, data fidelity, and regularization term\n",
    "    plt.plot(total_loss_history, label='Total Loss', color='b', linewidth=2)\n",
    "    plt.plot(data_fidelity_history, label='Data Fidelity', color='g', linestyle='--', linewidth=2)\n",
    "    plt.plot(regularization_history, label='Regularization (Smoothness)', color='r', linestyle='-.', linewidth=2)\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.title('Loss Function Components Over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the optimization loop\n",
    "plot_loss_components(total_loss_history, data_fidelity_history, regularization_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
